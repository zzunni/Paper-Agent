

===== Page 1 =====

Proceedings of the 2025 Winter Simulation Conference
E. Azar, A. Djanatliev, A. Harper, C. Kogler, V. Ramamohan, A. Anagnostou, and S. J. E. Taylor, eds.
CROSS-PROCESS DEFECT ATTRIBUTION USING POTENTIAL LOSS ANALYSIS
Tsuyoshi Id√©1, Kohei Miyaguchi2*
1IBM Semiconductors, IBM Thomas J. Watson Research Center, New York, USA.
2IBM Research ‚Äì Tokyo, Tokyo, Japan.
ABSTRACT
Cross-process root-cause analysis of wafer defects is among the most critical yet challenging tasks in
semiconductor manufacturing due to the heterogeneity and combinatorial nature of processes along the
processing route. This paper presents a new framework for wafer defect root cause analysis, called Potential
Loss Analysis (PLA), as a significant enhancement of the previously proposed partial trajectory regression
approach. The PLA framework attributes observed high wafer defect densities to upstream processes by
comparing the best possible outcomes generated by partial processing trajectories. We show that the task
of identifying the best possible outcome can be reduced to solving a Bellman equation. Remarkably, the
proposed framework can simultaneously solve the prediction problem for defect density as well as the
attribution problem for defect scores. We demonstrate the effectiveness of the proposed framework using
real wafer history data.
1
INTRODUCTION
The latest technology nodes in semiconductor manufacturing involve more than one thousand process steps
across about a dozen process types such as deposition and etching. Cross-process root-cause analysis
of wafer defects spanning the entire processing sequence is among the most critical yet challenging
tasks in semiconductor manufacturing. Particularly during process integration and yield ramp-up stages,
classical design-of-experiment methodologies, which analyze process outcomes across systematically varied
parameters, are often impractical due to the prohibitively large number of adjustable parameters along the
processing route. Although a wide range of off-the-shelf machine learning tools are publicly available,
most of these tools are designed for prediction tasks, such as estimating real-valued outputs (regression)
or categorical outcomes (classification). As a result, fab-wide defect diagnosis still heavily depends on
manual, ad hoc analysis by domain experts.
To support more systematic analysis, three major directions have been pursued in the semiconductor
analytics literature to date. The first approach treats defect diagnosis as a by-product of cross-process virtual
metrology (VM) modeling. Regularized linear regression combined with variable selection techniques is
commonly used (e.g., (Susto, Pampuri, Schirru, Beghi, and De Nicolao 2015; Jebri, El Adel, Graton,
Ouladsine, and Pinaton 2016; Kim, Kim, Jun, Chong, and Song 2018)). However, linear models struggle to
capture complex nonlinear relationships across heterogeneous fabrication processes. Furthermore, defect
attribution based on linear models is essentially reduced to variable-wise correlation analysis, which is
known to yield only weak attribution signals (Miyaguchi, Joko, Sheraw, and Id√© 2025a).
The second direction is to leverage recurrent neural networks (RNNs) and Transformers to replace
conventional VM models. While they can capture complex nonlinear dependencies in sequential processes
(e.g., (Yella, Zhang, Petrov, Huang, Qian, Minai, and Bom 2021; Han, et al. 2023; Dalla Zuanna, Gentner,
and Susto 2023; Lee and Kim 2020; Hsu and Lu 2023)), handling different processes requires significant
feature engineering effort. Additionally, they typically operate as black boxes, making input attribution a
*Kohei Miyaguchi is currently affiliated with LY Research, Japan.
arXiv:2508.00895v1  [eess.SY]  27 Jul 2025

===== Page 2 =====

Id√© and Miyaguchi
‚àíùëì 
ùõºùëò= ùëì 
k
‚Ä¶
k
‚Ä¶
‚Äúoptimal‚Äù downstream route
‚Äúoptimal‚Äù downstream route
‚Ä¶
‚Ä¶
Full processing route (length varies)
Wafer defect 
detection point
(a)
(b)
Figure 1: Problem setting and the key idea. (a) We are interested in identifying upstream processes
responsible for wafer defects detected at a specific detection point. The number of process steps along the
route can vary. (b) The key idea of the PLA approach. Instead of zeroing out the process embeddings on
the downstream path, it solves an optimization problem for optimal downstream routes.
non-trivial task. These models are also generally data-intensive, and it is often difficult to collect enough
data to cover the combinatorial complexity of the fabrication process.
The third direction involves leveraging explainable artificial intelligence (XAI) techniques applicable
to black-box prediction models. This is a promising direction in that it can potentially enhance expressive
prediction models with interpretability, helping to identify which process steps should be adjusted to
improve defect rates. However, for cross-process defect attribution, existing methods, such as those based
on Shapley values (e.g., (Torres, Kissiov, Essam, Hartig, Gardner, Jantzen, Schueler, and Niehoff 2020;
Senoner, Netland, and Feuerriegel 2022; Lee and Roh 2023; Guo and Chen 2024)), pay limited attention
to key characteristics of semiconductor processes, such as the sequential nature of fabrication steps. In
addition, they often rely on assumptions that may not be fully justifiable in semiconductor manufacturing,
such as dependence on arbitrarily selected baseline inputs. Ironically, these XAI approaches are often used
as yet another form of black-box reasoning without careful justifications.
Recently, a new framework called the partial trajectory regression (PTR) was proposed to address
these issues, such as capturing the sequential nature of fabrication and the lack of direct attribution
capability (Miyaguchi, Joko, Sheraw, and Id√© 2025b). However, similar to Shapley-value-based approaches,
its attribution mechanism still suffers from potential biases due to inappropriate model assumptions, as
discussed in detail later.
In this paper, we propose a novel framework called potential loss analysis (PLA), as a significant
enhancement over PTR. Figure 1 illustrates the key idea. Our goal is to attribute an observed wafer quality
issue by computing a responsibility score (or attribution score) for each upstream process. To evaluate the
influence of the k-th process, we compare counterfactual outcomes based on partial process routes with and
without the target process. The key idea is to use optimal downstream routes and compare the outcomes
from the best possible continuations. To identify such optimal routes, we formulate wafer processing as a
sequential decision-making problem and solve a Bellman equation. To the best of our knowledge, this is
the first work to introduce the notion of path optimization into wafer defect attribution. We demonstrate
the effectiveness of the proposed framework using real wafer history data from a state-of-the-art FEOL
(front-end-of-line) process.
2
RELATED WORK
This section provides more detailed context of the problem we address with a particular focus on cross-process
virtual metrology and explainable AI.
2.1 Cross-Process Virtual Metrology
A key characteristic that distinguishes semiconductor manufacturing from other industrial domains is its
process complexity. A typical semiconductor process involves more than hundreds of intricate and highly

===== Page 3 =====

Id√© and Miyaguchi
specialized physical operations, including photolithography, thermal annealing, polishing, wet and dry
etching, ion implantation, electroplating, sputtering, and chemical vapor deposition, among others.
For cross-process root-cause analysis, these heterogeneous operations must be mapped to a shared
representation space to enable meaningful comparisons. Existing literature offers three general approaches
for this. The first approach utilizes process trace data (Xu, Zhang, Sun, Chen, Qin, Lv, and Zhang 2024;
Fan, Hsu, Tsai, Chou, Jen, and Tsou 2022). While effective within individual process tools, this method
requires extensive tool-specific preprocessing, and the quality of analysis heavily depends on the chosen
preprocessing strategy, making it less suitable for cross-process analysis. The second approach uses inline
measurements as proxies for physical processes. Since these measurements partially absorb the physical
heterogeneity across processes, this method has become common practice in recent studies (Senoner,
Netland, and Feuerriegel 2022; Guo and Chen 2024; Wang and Chen 2024; Ni, Rui, Zhuo, Li, Wen, and
Nie 2025). However, these approaches typically disregard the sequential order of processes and perform
root-cause analysis as a by-product of virtual metrology (VM), often via univariate correlation analysis,
which is known to yield only weak attribution signals (Miyaguchi, Joko, Sheraw, and Id√© 2025a).
The third approach involves embedding techniques, where data objects (e.g., process steps) are transformed into numerical vector representations. For instance, Fan et al. (Fan, Lin, and Jen 2022) use one-hot
encoding to unify categorical and numerical data in the VM setting. Schulz et al. (Schulz, Jacobi, Gisbrecht,
Evangelos, Chan, and Gan 2022) propose defining a fab state vector using known interdependencies among
processing tools under an unsupervised setting, without the context of wafer defect analysis. More recently,
Miyaguchi et al. (Miyaguchi, Joko, Sheraw, and Id√© 2025b) proposed proc2vec and route2vec algorithms
that think of process attributes as synthetic words and capture their similarity using kernel embedding. The
proposed PLA framework uses their approach as a building block.
2.2 Explainable AI (XAI)
Numerous methods have been developed to improve the interpretability of machine learning models
under the umbrella of XAI (Xu, Uszkoreit, Du, Fan, Zhao, and Zhu 2019). One widely used category
is additive explanation methods (Lundberg and Lee 2017; Ribeiro, Singh, and Guestrin 2016), which
provide mathematically justified decompositions of a model‚Äôs output into individual contributions of input
variables. Other common XAI techniques include gradient-based methods (Selvaraju, Cogswell, Das,
Vedantam, Parikh, and Batra 2020) and attention-based methods (Ali, Schnake, Eberle, Montavon, M√ºller,
and Wolf 2022).
While most XAI studies have traditionally assumed vector inputs whose dimensions can be arbitrarily
reordered, a growing‚Äîthough still relatively limited‚Äîbody of research is beginning to address the unique
challenges posed by sequential data, particularly time-series data (Rojat, Puget, Filliat, Del Ser, Gelin, and
D√≠az-Rodr√≠guez 2021). In the specific field of semiconductor analytics, the integration of model-agnostic
XAI techniques with advanced VM models is emerging as a research trend, aiming to balance predictive
power with interpretability. Among the wide variety of XAI methods (see, e.g.,(Molnar 2020) for an
overview), the majority of recent studies adopt the Shapley value (Torres, Kissiov, Essam, Hartig, Gardner,
Jantzen, Schueler, and Niehoff 2020; Senoner, Netland, and Feuerriegel 2022; Lee and Roh 2023; Guo
and Chen 2024), possibly due to the availability of a well-designed Python implementation (Lundberg and
Lee 2017). Ironically, despite its widespread adoption, most studies apply XAI methods as black boxes,
without critically examining their modeling assumptions. In fact, mainstream attribution algorithms, such
as Shapley values and integrated gradients, provide attribution scores relative to an arbitrary reference
point. A similar issue arises in the PTR framework, as discussed later.
In contrast, the proposed PLA framework, which is based on our recent unpublished work (Miyaguchi
2025), completely eliminates the need for the arbitrary reference point, which we believe presents a major
step forward in XAI research.

===== Page 4 =====

Id√© and Miyaguchi
3
PRELIMINARIES
This section provides a formal definition of the attribution problem and an overview of partial trajectory
regression as the baseline approach.
3.1 Problem Setting
Our main goal is to develop a method for computing the attribution score of each process in a wafer‚Äôs
processing route, given an observed process outcome. To formulate the attribution model, we assume a
training dataset consisting of N pairs of (process outcome metric, processing route):
D ‚âú{(y(n),Œæ (n)) | n = 1,...,N},
Œæ (n) =

(x(n)
1 ,t(n)
1 ),...,(x(n)
L(n),t(n)
L(n))

,
(1)
where N is the number of wafers and the superscript (n) indicates that the quantity belongs to the n-th wafer.
The symbols Œæ and y denote a processing route (or trajectory) and the corresponding process outcome
metric, respectively. For y, we use log defect density in empirical evaluations. L denotes the number of
processes in route Œæ. Note that L may vary across wafers due to reworks or different route definitions.
Therefore, treating Œæ as a fixed-dimensional object is generally not appropriate.
Weassumethatprocessk (k = 1,...,L)hasavectorrepresentationxk ‚ààRD andanassociatedtimestamptk,
where D is the dimensionality of the representation space. While finding a common representation space
across all the processes is a nontrivial task, the kernel embedding method described in the next subsection
provides a practical solution.
Because the length of each trajectory varies, the index k only refers to the position of a process within
a given trajectory Œæ. For instance, the 10th process in Œæ (1) and the 10th process in Œæ (2) may correspond
to entirely different physical operations.
Formally, the task of process attribution is defined as follows:
Definition 3.1 (Process attribution). Find a function Œ±k(Œæ) that computes the responsibility score for the
k-th process on a process route instance Œæ (k = 1,...,L), which is generally not included in D.
3.2 Process Embedding
We assume that processes are represented by numerical vectors {xk}L
k=1. As discussed in the previous
section, this is a nontrivial task due to the heterogeneity of semiconductor processes, which include
etching, polishing, ion implantation, and more. Here, we adopt the kernel embedding approach proposed
by (Miyaguchi, Joko, Sheraw, and Id√© 2025b), assuming that high-level process attributes such as process
ID and recipe ID are available from the manufacturing execution system (MES).
We first extract common attributes from the MES across different processes, such as equipment IDs,
recipe IDs, tool types, photo layer IDs, route IDs, and others. We then create a synthetic ‚Äòtoken‚Äô for each
process by concatenating these strings as follows:
(process token) = eqp‚äïrecipe‚äïtool_type‚äïphoto_layer‚äïroute‚äï¬∑¬∑¬∑ ,
where ‚äïdenotes string concatenation with a suitable separator.
Based on these string representations, we construct a dictionary of tokens. Let Vd denote the size of the
vocabulary, i.e., the number of unique tokens. For this dictionary, we compute a kernel matrix K ‚ààRVd√óVd,
where Ki,j is the similarity between tokens i and j computed using a variant of the substring kernel (Lodhi,
Saunders, Shawe-Taylor, Cristianini, and Watkins 2002; Shawe-Taylor and Cristianini 2004). Once the
kernel matrix K is computed, the vector representation of token i is obtained as:
xi = (
‚àö
Œª 1v1,i,...,
‚àö
Œª kvk,i,...,
‚àö
Œª DvD,i)‚ä§,
(2)
where Œªk is the k-th largest eigenvalue of K, and vk,i is the i-th element of the eigenvector corresponding
to Œªk. D is a user-defined embedding dimensionality.

===== Page 5 =====

Id√© and Miyaguchi
ùë¶
‚Ä¶
‚Ä¶
ùë•1
ùë•2
ùë•3
ùë•4
ùë•ùêø
ùëß1
ùëß2
ùëß3
ùëß4
ùëßùêø
‡∑úùë¶
‚Ä¶
process
process 
embedding
Wafer state
Predicted 
outcome
Figure 2: Assumed state-space model of PLA. Each process has a vector representation called the process
embedding. The wafer state evolves based on the process embedding and the previous state.
3.3 Partial Trajectory Regression
With the process embeddings {xk} now represented in a D-dimensional space, we aim to build a predictive
model for defect density y as a function of the process vector sequence. This remains a nontrivial task due
to the variable length of trajectories, making it an instance of trajectory regression (Id√© and Kato 2009;
Id√© and Sugiyama 2011), distinct from standard regression problems.
In this work, we employ a state-space model as illustrated in Fig. 2. A general form of the model is
defined by an RNN architecture:
xk = Embed(processk),
zk = Cell(zk‚àí1,xk,tk),
(3)
where zk denotes the wafer state vector after applying the first k processes, and xk is the process embedding
from the previous section. tk denotes the timestamp associated with xk. The function Cell(¬∑) is typically
implemented as a neural network that computes a new wafer state from the previous state and current input
(xk,tk). While standard RNN cells such as Long Short-Term Memory (LSTM) or Gated Recurrent Unit
(GRU) can be used, it has been suggested that a custom lightweight architecture
zk = œà(tk,tk‚àí1)xk +zk‚àí1,
(4)
is preferable in wafer root-cause analysis scenarios due to the lack of sufficient wafer samples covering the
entire process variability (Miyaguchi, Joko, Sheraw, and Id√© 2025b). Here, œà(¬∑,¬∑) is a temporal weighting
function, set to log10(1+¬∑) in our experiments.
One notable property of the PTR architecture in Fig. 2 is its ability to make predictions based on partial
trajectories. This is achieved by training a regression model of the form:
fœÜ(zk) = MLPœÜ(zk),
(5)
where MLPœÜ is a multi-layer perceptron with parameters œÜ, trained to minimize the loss:
LPTR(œÜ) ‚âú1
2N
N
‚àë
n=1
L(n)
‚àë
k=1
1
L(n)

y(n) ‚àífœÜ(zk)
2
+Œ∑‚à•œÜ‚à•1,
(6)
where ‚à•¬∑‚à•1 denotes the ‚Ñì1 norm and Œ∑ is its regularization strength as a hyperparameter.
4
POTENTIAL LOSS ANALYSIS FRAMEWORK
This section begins by discussing the limitations of the PTR-based attribution strategy and proceeds to
introduce the proposed optimized potential outcome framework.

===== Page 6 =====

Id√© and Miyaguchi
4.1 Issues with PTR-based Attribution
The PTR framework provides a useful approach to cross-process defect attribution. As illustrated in Fig. 1,
the PTR attribution method computes the attribution score of process k by comparing two potential outcomes
defined by partial trajectories. Specifically, the attribution score of the k-th process in Œæ is computed as:
Œ±k(Œæ) = f(zk)‚àíf(zk‚àí1),
(PTR)
(7)
where f(¬∑) is a regression function used to predict the process outcome, as discussed in Sec. 3.3. Unless
f(zk) is an additive function over different ks, the score Œ±k(Œæ) should include not only single-process effects
but also multi-process correlations with upstream processes. This approach aligns with Rubin‚Äôs potential
outcome framework (Rubin 2005), as it simulates a counterfactual comparison with and without the target
process k, similar to the situation in randomized controlled trials.
A critical question, however, is whether the PTR attribution method (7) is able to isolate the effect of
process k alone, independent of all other factors. Notably, one can show that the prediction on a partial
trajectory is equivalent to that of the full trajectory with the downstream process vectors set to 0. This
follows from the equivalent form of Eq. (4):
zk = z0 +
k
‚àë
i=1
œà(ti,ti‚àí1)xi.
(8)
Thus, the full trajectory zL equals a partial trajectory zk if xk+1 = ¬∑¬∑¬∑ = xL = 0.
Since the scale and origin of the process vectors can be arbitrary, this "zeroing out" approach may
introduce biases into the attribution score. This is true, for example, when a dimension of xi represents
a binary indicator variable. While process-wise standardization might help mitigate this issue, such an
approach results in unwanted dependency of the attribution score on the population means, depending on
the prediction model adopted, as shown in Sec. 5 (see Fig. 4). This is the same type of issue encountered
with Shapley values, whose attribution scores are defined relative to an arbitrary reference point. We next
discuss how to eliminate this arbitrariness.
4.2 Defining Optimal Expected Cumulative Loss
The key idea of the proposed Potential Loss Analysis (PLA) framework is to use an optimized downstream
route rather than arbitrarily zeroing out the process embeddings.
Let F(zk | xk+1,...,xL) denote the predicted outcome starting from wafer state zk when the wafer follows
a downstream path xk+1,...,xL afterwards. We model this as a sequential decision-making problem, where
the next process xk+1 is chosen based on zk. Each action transitions the wafer state to a new state zk+1
and incurs a loss C(zk+1). We define the cumulative expected loss from state z1 as:
F(z1 | x1,x2,...) = E
"
‚àû
‚àë
t=1
C(zt) | z
#
,
(9)
where we used the numbering from one as the subscripts specify the relative positions within a trajectory.
Each transition (z,x) ‚Üíz‚Ä≤ may be affected by random factors.
We model such randomness using a
probability distribution p(z‚Ä≤ | z,x) and the expectation E[¬∑] is taken with respect to this distribution. We
assume that the transition terminates at zL ‚ààST, where ST denotes the set of terminal states. The wafer
state remains in an absorbing state s‚ä•after the terminal state:
p(z‚Ä≤ | z,x) = Œ¥(z‚Ä≤ ‚àís‚ä•)
for z ‚ààST or z = s‚ä•,
(10)
where Œ¥(¬∑) is the Dirac delta function.

===== Page 7 =====

Id√© and Miyaguchi
In our problem setting, the instantaneous loss function C(z) represents the defect density observed at
the terminal state. Formally, it is given by:
C(z) =
(
y(z),
z ‚ààST
0,
otherwise,
(11)
where y(z) is the observable defect density at the terminal state. From Eqs. (9) and (10), we have
F(z ‚ààST | x1,x2,...) = E[y(z)]
and
F(z = z‚ä•| x1,x2,...) = E[0+0+¬∑¬∑¬∑] = 0.
(12)
We now define the optimal expected cumulative loss, which serves as a replacement for f(¬∑) in Eq. (7):
F‚àó(z1) ‚âúmin
x1,x2,...F(z1 | x1,x2,...) = min
x1
(
C(z1)+‚àë
z2
p(z2 | z1,x1)F‚àó(z2)
)
.
(13)
This represents the best possible process outcome achievable by following an optimal process trajectory
from the specified initial state. Recurrent functional equations of this form are generally referred to as the
Bellman equation in control theory (Bertsekas 2012).
4.3 Deriving a Tractable Optimization Problem
The definition in Eq. (13) involves optimization over downstream trajectories. Fortunately, we can derive
a tractable alternative that, perhaps unexpectedly, solves both the regression and trajectory optimization
problems simultaneously.
One of the challenges with Eq. (13) is how to handle the nested min operator. We first note that
F‚àó(z) ‚â§C(z)+‚àë
z‚Ä≤
p(z‚Ä≤ | z,x)F‚àó(z‚Ä≤)
(14)
holds in a transition (z,x) ‚Üíz‚Ä≤ from any (z,x). Assuming deterministic transitions, we approximate F‚àó(z)
using a parametric model FŒ∏(z), where Œ∏ is a set of model parameters to be learned from the training data
D. Under the deterministic setting, the above inequality becomes:
FŒ∏(z) ‚â§C(z)+FŒ∏(z‚Ä≤),
(15)
where z‚Ä≤ is the next state resulting from applying process x to state z. The tightest fit is achieved by
maximizing FŒ∏(z), where the optimal Œ∏ may vary across the state z. To find the best fit overall, we seek
Œ∏ that maximizes the expected value of FŒ∏(¬∑) under the constraint (15):
max
Œ∏ ‚àë
z
œÅ(z)FŒ∏(z)
s.t.
FŒ∏(z) ‚â§C(z)+FŒ∏(z‚Ä≤),
‚àÄ(z ‚Üíz‚Ä≤),
(16)
where œÅ(z) denotes the empirical distribution of states in D. This approach is based on the linear Bellman
inequality formulation introduced in (De Farias and Van Roy 2003), and was discussed in the present
context in (Miyaguchi 2025) for the first time.
4.4 Solving the Optimization Problem
Incorporating Eq. (12), the constraint can be rewritten as:
FŒ∏(z) ‚â§C(z)+FŒ∏(z‚Ä≤)(1‚àíI(z‚Ä≤)),
(17)

===== Page 8 =====

Id√© and Miyaguchi
where I(z‚Ä≤) is an indicator that equals 1 if z‚Ä≤ = s‚ä•, and 0 otherwise. This constraint can be incorporated
into the objective as the TD (time difference)-style penalty:
max
Œ∏
R(Œ∏ | ¬µ),
R(Œ∏ | ¬µ) = ‚àë
z

¬µœÅ(z)FŒ∏(z)‚àí1
2
n
FŒ∏(z)‚àíC(z)‚àíFŒ∏(z‚Ä≤)(1‚àíI(z‚Ä≤))
o2
,
(18)
where ¬µ‚àí1 is a regularization hyperparameter. Exploiting the fact that the second term in the parenthesis
can be written as
1
2{...}2 =
n
(1‚àíI(z‚Ä≤))[FŒ∏(z)‚àíC(z)‚àíFŒ∏(z‚Ä≤)]+I(z‚Ä≤)[FŒ∏(z)‚àíC(z)]
o2
(19)
=
n
(1‚àíI(z‚Ä≤))[FŒ∏(z)‚àíFŒ∏(z‚Ä≤)]+I(z‚Ä≤)[FŒ∏(z)‚àíy(z)]
o2
(20)
and that I(z‚Ä≤)(1‚àíI(z‚Ä≤)) = 0 always holds, the final objective to be maximized is:
R(Œ∏ | ¬µ) = 1
N
N
‚àë
n=1
"
¬µ
L(n)
L(n)
‚àë
t=1
FŒ∏(z(n)
t )‚àí1
2
n
y(n) ‚àíFŒ∏(z(n)
L(n))
o2
‚àí1
2
L(n)‚àí1
‚àë
t=1
¬µi
n
FŒ∏(z(n)
t+1)‚àíFŒ∏(z(n)
t )
o2
#
,
(21)
where ¬µi is a hyperparameter that can be adjusted according to data quality. More detailed mathematical
analysis shows that the solution must satisfy FŒ∏(zt+1) ‚â•FŒ∏(zt). To ensure this, we employ a positive
output neural network for the difference:
GŒ∏(zt,zt+1) ‚âúFŒ∏(zt+1)‚àíFŒ∏(zt) = ReLUŒ∏(zt ‚äïzt+1),
(22)
where ‚äïdenotes vector concatenation and ReLUŒ∏ is the rectified linear unit activation function with a
neural network parameter set Œ∏. Equations (21) and (22) define the main optimization problem in the
proposed PLA framework.
4.5 Process Attribution with PLA Framework
The PLA framework defined by Eqs. (21) and (22) offers several unique advantages.
First, it directly provides the attribution score:
Œ±k(Œæ) ‚âúGŒ∏(zk‚àí1,zk)
(PLA),
(23)
which is guaranteed to be non-negative. Once we learned the model parameter Œ∏, this formula can be used
for any process route instance Œæ.
Second, the attribution score is derived from the comparison of best possible downstream outcomes
with and without the process of interest, eliminating the arbitrariness of zeroing out. As shown in the next
section (Fig. 4), this allows providing informative signals to wafers whose defect density is close to the
population mean.
Finally, the term
n
y(n) ‚àíFŒ∏(z(n)
L(n))
o2
in Eq. (21) ensures that FŒ∏(z) is a reasonable estimator of terminal
loss at z ‚ààST, allowing the PLA framework to solve not only the downstream path optimization problem
but also trajectory regression simultaneously.
5
EMPIRICAL EVALUATION
We applied the PLA framework to conduct root-cause analysis for a specific defect type in a state-ofthe-art FEOL process. The training dataset D was collected at the NY CREATES Albany NanoTech fab,
which consists of process histories for N = 787 wafers, covering hundreds of process steps, along with
corresponding defect density measurements obtained at a process-limited yield (PLY) evaluation point. We
implemented PLA in Python, where PyTorch 2.3.1 was used for the attribution function in Eq. (23).

===== Page 9 =====

Id√© and Miyaguchi
wafer_id: 9ae23c
wafer_id: 1d2273
route embedding
Figure 3: Process and route embeddings. Left: Distribution of process embeddings {xk}L
k=1 for two wafer
instances. Each process belongs to one of eight process types (wet process, rapid thermal processing,
inspection, lithography, reactive ion etching, ion implantation, furnace, chemical mechanical polishing),
which are color-coded. Right: Distribution of route embeddings {z(n)
L(n)}N
n=1 in the training dataset D, with
the top 10% highest-defect-density routes highlighted in red.
5.1 Process and Route Embedding
One of the critical challenges in cross-process defect attribution is the limited sample size relative to the
combinatorial complexity of processing routes. Process and route embedding aims to leverage partial
commonalities among routes to enable more robust prediction.
Figure 3 (a) shows the scatter plot of process embeddings for two wafer examples, with each point
corresponding to a process step along the route. The visualization was generated usingt-SNE as implemented
in scikit-learn (Van der Maaten and Hinton 2008) with perplexity 30. Clear clustering structures are observed,
suggesting that the string kernel embedding captures similarities between processing conditions effectively.
Points located in close proximity typically correspond to slightly different recipe versions applied on the
same tool type.
Figure 3 (b) shows route-level embeddings for all N = 787 wafers, where each point represents the
entire process history of a wafer. The figure exhibits numerous micro-clusters, many of which may originate
from lot-based processing patterns. Routes in the top 10% of defect density are highlighted in red. Notable
clusters in the upper region of the plot indicate the potential presence of systematic issues.
5.2 Process Attribution
Next, we compared the proposed PLA framework with PTR. As a baseline, we used a linear model in
Eq. (5), which yielded a moderate cross-validated correlation of 0.61 between predicted and ground truth
log defect density. In contrast, PLA, using a two-hidden-layer neural network in Eq. (22), achieved a
correlation efficient of 0.87, demonstrating a significantly improved capability for modeling the process
outcomes.
Figure 4 compares cumulative attribution scores between PTR and PLA for a wafer from the held-out
test set. Specifically, it plots the following quantities at each timestamp œÑ such that tk ‚â§œÑ:
k
‚àë
i=1
Œ±i + f(z0)
(PTR)
or
k
‚àë
i=1
Œ±i +FŒ∏(z0)
(PLA).
(24)
For PTR, the cumulative scores at the initial and terminal processes correspond to f(z1) and f(zL),
respectively. Similarly, for PLA, they correspond to FŒ∏(z1) and FŒ∏(zL). This visualization illustrates how
the predicted defect density, referred to as ‚Äòbadness‚Äô in the figure, accumulates throughout the process
sequence.

===== Page 10 =====

Id√© and Miyaguchi
Operation number
Operation number
Wafer badness
Wafer badness
Wafer A
Wafer B
(a) PTR 
(b) PTR
Cumulative score
                Observed badness
Cumulative score
                Observed badness
(C) PLA
(D) PLA
Figure 4: Comparison of PTR and PLA in terms of cumulative attribution scores. For Wafer A, the
PTR-based score in (a) fails to provide informative signals, while the PLA result in (c) clearly shows how
the wafer defectiveness accumulates along the route. For Wafer B, the negative attribution values in (b)
complicate interpretation, whereas PLA yields consistently interpretable scores thanks to the guaranteed
non-negativity.
PTR-based attribution exhibits ups and downs due to the absence of a monotonicity constraint. This is
particularly problematic for wafers with near-average defect density in Fig. 4 (a), as the score is computed
relative to the population mean due to its linear construction. In contrast, Figs. 4 (c) and (d) show that
PLA produces more stable and interpretable attribution curves.
In Fig. 4 (c) and (d), the marked upward jumps in the attribution curves were found to correspond to
unusually long wait times at specific tools, the latter of which was suspected to be the main contributor to
the defect type of interest. This result highlights how PLA can effectively pinpoint problematic processes
and provide actionable insights for root cause analysis.
6
CONCLUSION
We have proposed a new cross-process defect attribution framework, Potential Loss Analysis (PLA). The
PLA framework addresses a fundamental challenge in sequential manufacturing: how to evaluate the
responsibility of each process along the processing route.
We formalized the attribution task as a comparison of best-possible outcomes across two counterfactual
partial trajectories. To the best of our knowledge, this is the first work to show that the problem can be
reduced to solving a Bellman equation, enabling simultaneous regression and attribution.
Empirical evaluation on a state-of-the-art FEOL process demonstrated that PLA overcomes critical
limitations of the prior partial trajectory regression approach. PLA not only improves prediction accuracy
but also yields more reliable and interpretable attribution scores, making it a promising tool for data-driven,
cross-process root cause analysis in semiconductor manufacturing.

===== Page 11 =====

Id√© and Miyaguchi
ACKNOWLEDGEMENT
The authors gratefully acknowledge the support of NY CREATES and the Albany NanoTech Complex
for providing access to state-of-the-art fabrication and characterization resources. They also extend their
gratitude to Rebekah Sheraw, Monirul Islam, and Ishtiaq Ahsan for providing the PLY data and their
valuable support throughout the project.
REFERENCES
Ali, A., T. Schnake, O. Eberle, G. Montavon, K.-R. M√ºller, and L. Wolf. 2022. ‚ÄúXAI for transformers: Better
explanations through conservative propagation‚Äù. In International Conference on Machine Learning,
435‚Äì451. PMLR.
Bertsekas, D. 2012. Dynamic programming and optimal control: Volume I, Volume 4. Athena scientific.
Dalla Zuanna, F., N. Gentner, and G. A. Susto. 2023. ‚ÄúDeep Learning-based Sequence Modeling for
Advanced Process Control in Semiconductor Manufacturing‚Äù. IFAC-PapersOnLine 56(2):8744‚Äì8751.
De Farias, D. P., and B. Van Roy. 2003. ‚ÄúThe linear programming approach to approximate dynamic
programming‚Äù. Operations research 51(6):850‚Äì865.
Fan, S.-K. S., C.-Y. Hsu, D.-M. Tsai, M. C. Chou, C.-H. Jen, and J.-H. Tsou. 2022. ‚ÄúKey feature identification for monitoring wafer-to-wafer variation in semiconductor manufacturing‚Äù. IEEE Transactions
on Automation Science and Engineering 19(3):1530‚Äì1541.
Fan, S.-K. S., W.-K. Lin, and C.-H. Jen. 2022. ‚ÄúData-driven optimization of accessory combinations for final
testing processes in semiconductor manufacturing‚Äù. Journal of Manufacturing Systems 63:275‚Äì287.
Guo, P., and Y. Chen. 2024. ‚ÄúEnhanced Yield Prediction in Semiconductor Manufacturing: Innovative
Strategies for Imbalanced Sample Management and Root Cause Analysis‚Äù. In 2024 IEEE International
Symposium on the Physical and Failure Analysis of Integrated Circuits (IPFA), 1‚Äì6. IEEE.
Han, et al., S. 2023. ‚ÄúDeep learning-based virtual metrology in multivariate time series‚Äù. In 2023 IEEE
International Conference on Prognostics and Health Management (ICPHM), 30‚Äì37. IEEE.
Hsu, C.-Y., and Y.-W. Lu. 2023. ‚ÄúVirtual metrology of material removal rate using a one-dimensional
convolutional neural network-based bidirectional long short-term memory network with attention‚Äù.
Computers & Industrial Engineering 186:109701.
Id√©, T., and S. Kato. 2009. ‚ÄúTravel-time prediction using Gaussian process regression: A trajectory-based
approach‚Äù. In Proceedings of the 2009 SIAM International Conference on Data Mining, 1185‚Äì1196.
Id√©, T., and M. Sugiyama. 2011. ‚ÄúTrajectory regression on road networks‚Äù. In Proceedings of the AAAI
Conference on Artificial Intelligence, Volume 25, 203‚Äì208.
Jebri, M. A., E. El Adel, G. Graton, M. Ouladsine, and J. Pinaton. 2016. ‚ÄúVirtual metrology on semiconductor
manufacturing based on Just-in-time learning‚Äù. IFAC-PapersOnLine 49(12):89‚Äì94.
Kim, K.-J., K.-J. Kim, C.-H. Jun, I.-G. Chong, and G.-Y. Song. 2018. ‚ÄúVariable selection under missing values and unlabeled data in semiconductor processes‚Äù. IEEE Transactions on Semiconductor
Manufacturing 32(1):121‚Äì128.
Lee, K. B., and C. O. Kim. 2020. ‚ÄúRecurrent feature-incorporated convolutional neural network for
virtual metrology of the chemical mechanical planarization process‚Äù. Journal of Intelligent Manufacturing 31(1):73‚Äì86.
Lee, Y., and Y. Roh. 2023. ‚ÄúAn Expandable Yield Prediction Framework Using Explainable Artificial
Intelligence for Semiconductor Manufacturing‚Äù. Applied Sciences 13(4):2660.
Lodhi, H., C. Saunders, J. Shawe-Taylor, N. Cristianini, and C. Watkins. 2002. ‚ÄúText classification using
string kernels‚Äù. Journal of machine learning research 2(Feb):419‚Äì444.
Lundberg, S. M., and S.-I. Lee. 2017. ‚ÄúA unified approach to interpreting model predictions‚Äù. In Proceedings
of the 31st International Conference on Neural Information Processing Systems, 4768‚Äì4777.
Miyaguchi,
K.
2025.
‚ÄúPath
Learning
with
Trajectory
Advantage
Regression‚Äù.
arXiv
preprint
arXiv:2506.19375 https://doi.org/10.48550/arXiv.2506.19375.

===== Page 12 =====

Id√© and Miyaguchi
Miyaguchi, K., M. Joko, R. Sheraw, and T. Id√©. 2025a. ‚ÄúSequence-Aware Inline Measurement Attribution for
Good-Bad Wafer Diagnosis‚Äù. In Proceedings of the 2025 SEMI Advanced Semiconductor Manufacturing
Conference (ASMC). IEEE https://doi.org/10.1109/ASMC64512.2025.11010308.
Miyaguchi, K., M. Joko, R. Sheraw, and T. Id√©. 2025b. ‚ÄúWafer Defect Root Cause Analysis using
partial trajectory regression‚Äù. In 2025 SEMI Advanced Semiconductor Manufacturing Conference
(ASMC) https://doi.org/10.1109/ASMC64512.2025.11010733.
Molnar, C. 2020. Interpretable machine learning. Lulu.com.
Ni, T., W. Rui, C. Zhuo, Y. Li, X. Wen, and M. Nie. 2025. ‚ÄúA Novel Approach to Reducing Testing Costs
and Minimizing Defect Escapes Using Dynamic Neighborhood Range and Shapley Values‚Äù. ACM
Transactions on Design Automation of Electronic Systems.
Ribeiro, M. T., S. Singh, and C. Guestrin. 2016. ‚Äú‚ÄòWhy Should I Trust You?‚Äô: Explaining the Predictions
of Any Classifier‚Äù. In Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge
Discovery and Data Mining, KDD ‚Äô16, 1135‚Äì1144. New York, NY, USA.
Rojat, T., R. Puget, D. Filliat, J. Del Ser, R. Gelin, and N. D√≠az-Rodr√≠guez. 2021. ‚ÄúExplainable artificial
intelligence (XAI) on timeseries data: A survey‚Äù. arXiv preprint arXiv:2104.00950.
Rubin, D. B. 2005. ‚ÄúCausal inference using potential outcomes: Design, modeling, decisions‚Äù. Journal of
the American statistical Association 100(469):322‚Äì331.
Schulz, B., C. Jacobi, A. Gisbrecht, A. Evangelos, C. W. Chan, and B. P. Gan. 2022. ‚ÄúGraph representation
and embedding for semiconductor manufacturing fab states‚Äù. In 2022 Winter Simulation Conference
(WSC), 3382‚Äì3393. IEEE.
Selvaraju, R. R., M. Cogswell, A. Das, R. Vedantam, D. Parikh, and D. Batra. 2020. ‚ÄúGrad-CAM: visual
explanations from deep networks via gradient-based localization‚Äù. International journal of computer
vision 128:336‚Äì359.
Senoner, J., T. Netland, and S. Feuerriegel. 2022. ‚ÄúUsing explainable artificial intelligence to improve process
quality: evidence from semiconductor manufacturing‚Äù. Management Science 68(8):5704‚Äì5723.
Shawe-Taylor, J., and N. Cristianini. 2004. Kernel methods for pattern analysis. Cambridge Univ. press.
Susto, G. A., S. Pampuri, A. Schirru, A. Beghi, and G. De Nicolao. 2015. ‚ÄúMulti-step virtual metrology for
semiconductor manufacturing: A multilevel and regularization methods-based approach‚Äù. Computers
& Operations Research 53:328‚Äì337.
Torres, J. A., I. Kissiov, M. Essam, C. Hartig, R. Gardner, K. Jantzen, et al. 2020. ‚ÄúMachine Learning
Assisted New Product Setup‚Äù. In 2020 31st Annual SEMI Advanced Semiconductor Manufacturing
Conference (ASMC), 1‚Äì5.
Van der Maaten, L., and G. Hinton. 2008. ‚ÄúVisualizing data using t-SNE.‚Äù. Journal of machine learning
research 9(11).
Wang, S., and Y. Chen. 2024. ‚ÄúImproved Yield Prediction and Failure Analysis in Semiconductor Manufacturing with XGBoost and Shapley Additive exPlanations Models‚Äù. In 2024 IEEE International
Symposium on the Physical and Failure Analysis of Integrated Circuits (IPFA), 01‚Äì08. IEEE.
Xu, F., H. Uszkoreit, Y. Du, W. Fan, D. Zhao, and J. Zhu. 2019. ‚ÄúExplainable AI: A brief survey on history,
research areas, approaches and challenges‚Äù. In Proceedings of the 8th cCF international conference
on Natural language processing and Chinese computing, part II 8, 563‚Äì574.
Xu, H.-W., Q.-H. Zhang, Y.-N. Sun, Q.-L. Chen, W. Qin, Y.-L. Lv et al. 2024. ‚ÄúA fast ramp-up framework
for wafer yield improvement in semiconductor manufacturing systems‚Äù. Journal of Manufacturing
Systems 76:222‚Äì233.
Yella, J., C. Zhang, S. Petrov, Y. Huang, X. Qian, A. A. Minai et al. 2021. ‚ÄúSoft-sensing conformer: A
curriculum learning-based convolutional transformer‚Äù. In 2021 IEEE International Conference on Big
Data (Big Data), 1990‚Äì1998. IEEE.
